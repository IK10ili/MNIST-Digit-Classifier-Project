{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee049b5-2ed8-4d81-b527-d1d2bf5768c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee380ee-d9c8-4ca7-af03-0ef50ce9fe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ffafbc7-3090-4bff-9698-d7c1617b4535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Preprocess the Data\n",
    "\n",
    "# Load the dataset using torchvision.datasets.MNIST\n",
    "# Apply transformations (ToTensor() and normalization)\n",
    "# Create DataLoader objects for training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8fcf73-403f-4f62-acda-52abef3c3b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in c:\\users\\ikili\\python anaconda\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torchvision) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from torch==2.6.0->torchvision) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from sympy==1.13.1->torch==2.6.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ikili\\python anaconda\\lib\\site-packages (from jinja2->torch==2.6.0->torchvision) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df3f616b-0ab9-4ded-a373-63bc72f9f49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f9d41c-ff99-42ab-960f-9bcbf7d06e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 60000\n",
      "Number of test samples: 10000\n"
     ]
    }
   ],
   "source": [
    "# Define transformations: Convert to Tensor and Normalize\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1] range\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=True, transform=transform, download=True\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root=\"./data\", train=False, transform=transform, download=True\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64  # Batch size for training\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Check dataset size\n",
    "print(f\"Number of training samples: {len(train_dataset)}\")\n",
    "print(f\"Number of test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feec1eed-690d-4fff-8681-2370b663fe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "# ToTensor() → Converts images to PyTorch tensors.\n",
    "# Normalize((0.5,), (0.5,)) → Normalizes pixel values - to stabilize training.\n",
    "# train=True and train=False → Loads the training and test datasets separately.\n",
    "# DataLoader → Batches and shuffles data for efficient processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12bfd2a-0ba3-49c4-a48b-c11171bed9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Visualizing and Exploring the Data\n",
    "\n",
    "# Check the shape and size of the dataset.\n",
    "# Visualize sample images to understand how the input looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6347fdf-5e2b-42c2-9afb-df2aa46a70b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check dataset properties\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m sample_image, sample_label \u001b[38;5;241m=\u001b[39m train_dataset[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Get first sample\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of a single image tensor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_image\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Should be [1, 28, 28]\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel of the first image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# Check dataset properties\n",
    "sample_image, sample_label = train_dataset[0]  # Get first sample\n",
    "\n",
    "print(f\"Shape of a single image tensor: {sample_image.shape}\")  # Should be [1, 28, 28]\n",
    "print(f\"Label of the first image: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c493d154-0143-443e-ae50-1f9671c1ba8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 21\u001b[0m\n\u001b[0;32m     18\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Display sample images\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m show_images(train_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Function to denormalize and show images\n",
    "def show_images(dataset, num_images=6):\n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(10, 3))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        image, label = dataset[i]\n",
    "        \n",
    "        # Convert tensor to numpy array for visualization\n",
    "        image = image.numpy().squeeze()  # Remove extra dimension\n",
    "        \n",
    "        axes[i].imshow(image, cmap=\"gray\")\n",
    "        axes[i].set_title(f\"Label: {label}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Display sample images\n",
    "show_images(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "530a7442-af2d-4fc9-8ffb-f6c54cb45390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()  # Clears GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ac4e7f5-c84d-4929-be47-4e15ec968f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90597ba-2b9f-43d2-99e9-7be3168f191a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6a28cbd-8bc6-44a6-a833-4c6eeee56e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Building the Neural Network using PyTorch\n",
    "\n",
    "# Define a neural network using torch.nn.Module\n",
    "# Select a loss function and optimizer\n",
    "# Train the model using the training DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f7e702-0b14-4ceb-8a65-ef0063c1e23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Neural Network\n",
    "# use a simple fully connected feedforward network with:\n",
    "\n",
    "# Input layer: 784 neurons (flattened 28x28 images)\n",
    "# Hidden layers: 2 layers with 128 and 64 neurons\n",
    "# Activation function: ReLU (for non-linearity)\n",
    "# Output layer: 10 neurons (one for each digit 0-9) with softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb5239e3-8449-4e5d-b17e-8fead80cafd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNISTClassifier(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the neural network\n",
    "class MNISTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTClassifier, self).__init__()\n",
    "        self.flatten = nn.Flatten()  # Flatten 28x28 images to 1D\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)  # Second hidden layer\n",
    "        self.output = nn.Linear(64, 10)  # Output layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = torch.relu(self.fc1(x))  # ReLU activation\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.output(x)  # No softmax (handled in loss function)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = MNISTClassifier()\n",
    "\n",
    "# Print model architecture\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29cb087-0592-44e4-b3b2-337bc4bbee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Suitable for multi-class classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adaptive learning rate optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224c4f3b-76dc-42d6-b366-a444a1dceb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "# Iterate through train_loader\n",
    "# Compute loss\n",
    "# Backpropagate to update weights\n",
    "# Print loss every few epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7571835-67b8-40cc-9ac1-4096d6c3454d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      8\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     11\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move to GPU if available\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()  \u001b[38;5;66;03m# Reset gradients\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10  # Number of times the model sees the entire dataset\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)  # Move to GPU if available\n",
    "        \n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(images)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "        loss.backward()  # Backpropagation\n",
    "        optimizer.step()  # Update weights\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68353d07-8c3d-4dd3-94e6-c949f3ca7107",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      8\u001b[0m     running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m images, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     10\u001b[0m         images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m         optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Step 4: Training the Model\n",
    "epochs = 5  # Reduce epochs to prevent memory overload\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba27f4f1-d08c-4f9f-9e3e-4c31203ce538",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m---> 17\u001b[0m evaluate_model(model, test_loader)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Step 6: Save the Model\u001b[39;00m\n\u001b[0;32m     20\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model\u001b[38;5;241m.\u001b[39mstate_dict(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmnist_model.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Evaluating the Model\n",
    "def evaluate_model(model, test_loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy\n",
    "\n",
    "evaluate_model(model, test_loader)\n",
    "\n",
    "# Step 6: Save the Model\n",
    "torch.save(model.state_dict(), \"mnist_model.pth\")\n",
    "print(\"Model Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cb4f5a-f0e5-4cc8-9c88-15b14bbcaf8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42d421b-47bc-4a54-ac4d-4796b99fb77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
